{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "OK\n",
      "{'Date': 'Fri, 09 Aug 2019 04:21:47 GMT', 'Server': 'Apache/2.4.18 (Ubuntu)', 'Content-Type': 'text/html; charset=UTF-8', 'Content-Length': '20', 'Connection': 'keep-alive'}\n",
      "<PreparedRequest [GET]>\n",
      "{'User-Agent': 'python-requests/2.21.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n",
      "Hello from the web!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://www.webscrapingfordatascience.com/basichttp/'\n",
    "r = requests.get(url)\n",
    "\n",
    "# Which HTTP status code did we get back from the server?\n",
    "print(r.status_code)\n",
    "# What is the textual status code?\n",
    "print(r.reason)\n",
    "# What were the HTTP response headers?\n",
    "print(r.headers)\n",
    "\n",
    "# The request information is saved as a Python object in r.request:\n",
    "print(r.request)\n",
    "# What were the HTTP request headers?\n",
    "print(r.request.headers)\n",
    "\n",
    "# The HTTP response content:\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML and CSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://en.wikipedia.org/w/index.php' + \\\n",
    "'?title=List_of_Game_of_Thrones_episodes&oldid=802553687'\n",
    "\n",
    "r = requests.get(url)\n",
    "#print(r.text)\n",
    "html_contents = r.text\n",
    "html_soup = BeautifulSoup(html_contents, 'html.parser' )\n",
    "\n",
    "type(html_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"firstHeading\" id=\"firstHeading\" lang=\"en\">List of <i>Game of Thrones</i> episodes</h1>\n",
      "<div id=\"p-logo\" role=\"banner\"><a class=\"mw-wiki-logo\" href=\"/wiki/Main_Page\" title=\"Visit the main page\"></a></div>\n"
     ]
    }
   ],
   "source": [
    "# find(name, attrs, recursive, string, **keywords);\n",
    "# find_all(name, attrs, recursive, string, limit, **keywords)\n",
    "\n",
    "print( html_soup.find('h1'))\n",
    "print(html_soup.find('', {'id': 'p-logo'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"firstHeading\" id=\"firstHeading\" lang=\"en\">List of <i>Game of Thrones</i> episodes</h1>\n",
      "<h2>Contents</h2>\n",
      "<h2><span class=\"mw-headline\" id=\"Series_overview\">Series overview</span></h2>\n",
      "<h2><span class=\"mw-headline\" id=\"Episodes\">Episodes</span></h2>\n",
      "<h2><span class=\"mw-headline\" id=\"Home_media_releases\">Home media releases</span></h2>\n",
      "<h2><span class=\"mw-headline\" id=\"Ratings\">Ratings</span></h2>\n",
      "<h2><span class=\"mw-headline\" id=\"References\">References</span></h2>\n",
      "<h2><span class=\"mw-headline\" id=\"External_links\">External links</span></h2>\n",
      "<h2>Navigation menu</h2>\n"
     ]
    }
   ],
   "source": [
    "for found in html_soup.find_all(['h1', 'h2']):\n",
    "    print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'No.overall': '1', 'No. inseason': '1', 'Title': '\"Winter Is Coming\"', 'Directed by': 'Tim Van Patten', 'Written by': 'David Benioff & D. B. Weiss', 'Original air date\\u200a[20]': 'April\\xa017,\\xa02011\\xa0(2011-04-17)', 'U.S. viewers(millions)': '2.22[21]'}\n",
      "-------------\n",
      "{'No.overall': '2', 'No. inseason': '2', 'Title': '\"The Kingsroad\"', 'Directed by': 'Tim Van Patten', 'Written by': 'David Benioff & D. B. Weiss', 'Original air date\\u200a[20]': 'April\\xa024,\\xa02011\\xa0(2011-04-24)', 'U.S. viewers(millions)': '2.20[22]'}\n",
      "-------------\n",
      "{'No.overall': '3', 'No. inseason': '3', 'Title': '\"Lord Snow\"', 'Directed by': 'Brian Kirk', 'Written by': 'David Benioff & D. B. Weiss', 'Original air date\\u200a[20]': 'May\\xa01,\\xa02011\\xa0(2011-05-01)', 'U.S. viewers(millions)': '2.44[23]'}\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# We'll use a list to store our episode list\n",
    "episodes = []\n",
    "\n",
    "ep_tables = html_soup.find_all('table', class_=\"wikiepisodetable\")\n",
    "\n",
    "for table in ep_tables:\n",
    "    headers = []\n",
    "    rows = table.find_all('tr')\n",
    "    # Start by fetching the header cells from the first row to determine\n",
    "    # the field names\n",
    "    for header in table.find('tr').find_all('th'):\n",
    "        headers.append(header.text)\n",
    "    # Then go through all the rows except the first one\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        values = []\n",
    "        # And get the column cells, the first one being inside a th-tag\n",
    "        for col in row.find_all(['th','td']):\n",
    "            values.append(col.text)\n",
    "        if values:\n",
    "            episode_dict = {headers[i]: values[i] for i in range(len(values))}\n",
    "            episodes.append(episode_dict)\n",
    "            \n",
    "# Show the results\n",
    "for i,episode in enumerate(episodes):\n",
    "    if i == 3:\n",
    "        break\n",
    "    print(episode)\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using POST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "\t<body>\n",
      "\n",
      "\n",
      "<h2>Thanks for submitting your information</h2>\n",
      "\n",
      "<p>Here's a dump of the form data that was submitted:</p>\n",
      "\n",
      "<pre>array(5) {\n",
      "  [\"name\"]=>\n",
      "  string(5) \"Seppe\"\n",
      "  [\"gender\"]=>\n",
      "  string(1) \"M\"\n",
      "  [\"pizza\"]=>\n",
      "  string(4) \"like\"\n",
      "  [\"haircolor\"]=>\n",
      "  string(5) \"brown\"\n",
      "  [\"comments\"]=>\n",
      "  string(0) \"\"\n",
      "}\n",
      "</pre>\n",
      "\n",
      "\n",
      "\t</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.webscrapingfordatascience.com/postform2/'\n",
    "\n",
    "# First perform a GET request\n",
    "r = requests.get(url)\n",
    "\n",
    "# Followed by a POST request\n",
    "formdata = {\n",
    "    'name': 'Seppe',\n",
    "    'gender': 'M',\n",
    "    'pizza': 'like',\n",
    "    'haircolor': 'brown',\n",
    "    'comments': ''\n",
    "    }\n",
    "\n",
    "r = requests.post(url, data=formdata)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems you are using a scraper!\n",
      "{'User-Agent': 'python-requests/2.21.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://www.webscrapingfordatascience.com/usercheck/'\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "print(r.text)\n",
    "# Shows: It seems you are using a scraper\n",
    "\n",
    "print(r.request.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems you are using a scraper!\n",
      "{'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36  (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive'}\n"
     ]
    }
   ],
   "source": [
    "my_headers = {\n",
    "  'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 ' + ' (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'\n",
    "}\n",
    "\n",
    "r = requests.get(url, headers=my_headers)\n",
    "\n",
    "print(r.text) # it's using another link\n",
    "print(r.request.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems you are using a scraper!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_headers = {\n",
    "  'Referer': 'http://www.webscrapingfordatascience.com/referercheck/'\n",
    "}\n",
    "\n",
    "r = requests.get(url, headers=my_headers)\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a totally secret page\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.webscrapingfordatascience.com/referercheck/secret.php'\n",
    "\n",
    "my_headers = {\n",
    "  'Referer': 'http://www.webscrapingfordatascience.com/referercheck/'\n",
    "}\n",
    "\n",
    "r = requests.get(url, headers=my_headers)\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, there -- you've been redirected here from another page!\n",
      "\n",
      "{'Date': 'Fri, 09 Aug 2019 04:39:56 GMT', 'Server': 'Apache/2.4.18 (Ubuntu)', 'Content-Type': 'text/html; charset=UTF-8', 'Content-Length': '63', 'Connection': 'keep-alive'}\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.webscrapingfordatascience.com/redirect/'\n",
    "r = requests.get(url)\n",
    "\n",
    "print(r.text)\n",
    "print(r.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be redirected... bye bye!\n",
      "{'Date': 'Fri, 09 Aug 2019 04:40:14 GMT', 'Server': 'Apache/2.4.18 (Ubuntu)', 'SECRET-CODE': '1234', 'Location': 'http://www.webscrapingfordatascience.com/redirect/destination.php', 'Content-Type': 'text/html; charset=UTF-8', 'Content-Length': '34', 'Connection': 'keep-alive'}\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.webscrapingfordatascience.com/redirect/'\n",
    "r = requests.get(url, allow_redirects=False)\n",
    "\n",
    "print(r.text)\n",
    "print(r.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello harsha.\n",
      "You entered test as your password.\n",
      "{'User-Agent': 'python-requests/2.21.0', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Authorization': 'Basic aGFyc2hhOnRlc3Q='}\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.webscrapingfordatascience.com/authentication/'\n",
    "\n",
    "r = requests.get(url, auth=('harsha', 'test'))\n",
    "\n",
    "print(r.text)\n",
    "print(r.request.headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Cookies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hmm... it seems you are not logged in\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://www.webscrapingfordatascience.com/cookielogin/secret.php'\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>404 Not Found</title>\n",
      "</head><body>\n",
      "<h1>Not Found</h1>\n",
      "<p>The requested URL /cookielogin/secret.phpsecret.php was not found on this server.</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.18 (Ubuntu) Server at www.webscrapingfordatascience.com Port 80</address>\n",
      "</body></html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First perform a POST request\n",
    "r = requests.post(url, data={'username': 'dummy', 'password': '1234'})\n",
    "\n",
    "# Get the cookie value, either from\n",
    "# r.headers or r.cookies print(r.cookies)\n",
    "my_cookies = r.cookies\n",
    "\n",
    "# r.cookies is a RequestsCookieJar object which can also\n",
    "# be accessed like a dictionary. The following also works:\n",
    "my_cookies['PHPSESSID'] = r.cookies.get('PHPSESSID')\n",
    "\n",
    "# Now perform a GET request to the secret page using the cookies\n",
    "r = requests.get(url + 'secret.php', cookies=my_cookies)\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RequestsCookieJar[<Cookie PHPSESSID=qbfo0qtp4e09g2bi75pi07hat7 for www.webscrapingfordatascience.com/>]>\n",
      "This is a secret code: 1234\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.webscrapingfordatascience.com/redirlogin/'\n",
    "\n",
    "# First perform a POST request -- do not follow the redirect\n",
    "r = requests.post(url, data={'username': 'dummy', 'password': '1234'},\n",
    "                  allow_redirects=False)\n",
    "\n",
    "# Get the cookie value, either from r.headers or r.cookies\n",
    "print(r.cookies)\n",
    "\n",
    "my_cookies = r.cookies\n",
    "\n",
    "# Now perform a GET request manually to the secret page using the cookies\n",
    "r = requests.get(url + 'secret.php', cookies=my_cookies)\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should login first before accessing the protected page!\n",
      "<br><br>\n",
      "<form method=\"post\" action=\"index.php?p=login\">\n",
      "\tUsername: <input type=\"text\" name=\"username\"><br>\n",
      "\tPassword: <input type=\"password\" name=\"password\"><br>\n",
      "\t<input type=\"Submit\" value=\"Access the secret page\">\n",
      "</form>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = 'http://www.webscrapingfordatascience.com/trickylogin/'\n",
    "\n",
    "# First perform a normal GET request to get the form\n",
    "r = requests.post(url)\n",
    "\n",
    "# Then perform the POST request -- do not follow the redirect\n",
    "r = requests.post(url, params={'p': 'login'},\n",
    "                  data={'username': 'dummy', 'password': '1234'},\n",
    "                  allow_redirects=False)\n",
    "\n",
    "# Set the cookies\n",
    "my_cookies = r.cookies\n",
    "\n",
    "# Now perform a GET request manually to the secret page using the cookies\n",
    "r = requests.get(url, params={'p': 'protected'}, cookies=my_cookies)\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RequestsCookieJar[<Cookie PHPSESSID=vllf79hb909hh1tr744875pih2 for www.webscrapingfordatascience.com/>]>\n",
      "<RequestsCookieJar[<Cookie PHPSESSID=v7vo03du4g8dr0vhicabjcef17 for www.webscrapingfordatascience.com/>]>\n",
      "Here is your secret code: 3838.\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.webscrapingfordatascience.com/trickylogin/'\n",
    "\n",
    "# First perform a normal GET request to get the form\n",
    "r = requests.post(url)\n",
    "\n",
    "# Set the cookies\n",
    "my_cookies = r.cookies\n",
    "print(my_cookies)\n",
    "\n",
    "# Then perform the POST request -- do not follow the redirect\n",
    "# Use the cookies we got before\n",
    "r = requests.post(url, params={'p': 'login'},\n",
    "                  data={'username': 'dummy', 'password': '1234'},\n",
    "                  allow_redirects=False,\n",
    "                  cookies=my_cookies)\n",
    "\n",
    "# We need to update our cookies again\n",
    "# Note that the PHPSESSID value will have changed\n",
    "my_cookies = r.cookies\n",
    "print(my_cookies)\n",
    "\n",
    "# Now perform a GET request manually to the secret page\n",
    "# using the updated cookies\n",
    "r = requests.get(url, params={'p': 'protected'}, cookies=my_cookies)\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Session with requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is your secret code: 3838.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://www.webscrapingfordatascience.com/trickylogin/'\n",
    "\n",
    "my_session = requests.Session()\n",
    "\n",
    "r = my_session.post(url)\n",
    "r = my_session.post(url, params={'p': 'login'}, data={'username': 'harsha', 'password': '1234'})\n",
    "r = my_session.get(url, params={'p': 'protected'})\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'User-Agent': 'Chrome!', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Length': '0'}\n",
      "{'User-Agent': 'Chrome!', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Cookie': 'PHPSESSID=o74av9nnmrri15nvc04jn2jfh7'}\n",
      "{'User-Agent': 'Chrome!', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Cookie': 'PHPSESSID=de501j1hm14idq2cgk7fkbjm31'}\n"
     ]
    }
   ],
   "source": [
    "# clean session\n",
    "# my_session.cookies.clear()\n",
    "\n",
    "my_session = requests.Session()\n",
    "my_session.headers.update({'User-Agent': 'Chrome!'})\n",
    "\n",
    "# All requests in this session will now use this User-Agent header:\n",
    "\n",
    "r = my_session.post(url)\n",
    "print(r.request.headers)\n",
    "\n",
    "r = my_session.post(url, params={'p': 'login'},\n",
    "                    data={'username': 'dummy', 'password': '1234'})\n",
    "print(r.request.headers)\n",
    "\n",
    "r = my_session.get(url, params={'p': 'protected'})\n",
    "print(r.request.headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
